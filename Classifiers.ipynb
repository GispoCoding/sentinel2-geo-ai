{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumption\n",
    "\n",
    "Data is given in such a format that each data row represents one pixel in one satellite image. One row consists of 13 band values and a label associated with the particular pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First satellite image\n",
    "with open('PNL_A018780_20201010_60m.csv', 'rb') as fd1:\n",
    "    gzip_fd1 = gzip.GzipFile(fileobj=fd1)\n",
    "    data1 = pd.read_csv(gzip_fd1)\n",
    "\n",
    "# Check print\n",
    "#print(data1.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second satellite image\n",
    "with open('PQM_A018880_20201017_60m.csv', 'rb') as fd2:\n",
    "    gzip_fd2 = gzip.GzipFile(fileobj=fd2)\n",
    "    data2 = pd.read_csv(gzip_fd2)\n",
    "\n",
    "# Check print\n",
    "#print(data2.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's combine the pixels of the separately downloaded training satellite images\n",
    "# NOTE. You could download more images (and thus construct a larger training set) if you wish\n",
    "data = pd.concat([data1, data2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xallpd = data.iloc[:, 2:]\n",
    "indpd = data.iloc[:,0]\n",
    "yallpd = data.iloc[:,1]\n",
    "\n",
    "# Check prints\n",
    "#print(xallpd.iloc[3])\n",
    "#print(indpd.iloc[3])\n",
    "#print(yallpd.iloc[3])\n",
    "#print(xallpd.shape)\n",
    "#print(yallpd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform the pandas dataframes into numpy arrays and convert the labels from 1/2 to 0/1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xall = pd.DataFrame(xallpd).to_numpy()\n",
    "indall = pd.DataFrame(indpd).to_numpy()\n",
    "yall = pd.DataFrame(yallpd).to_numpy()\n",
    "\n",
    "# Check prints\n",
    "#print(np.shape(xall))\n",
    "#print(np.shape(yall))\n",
    "\n",
    "#print(np.count_nonzero(yall==1))\n",
    "#print(np.count_nonzero(yall==2))\n",
    "\n",
    "yall[yall==1] = 0\n",
    "yall[yall==2] = 1\n",
    "\n",
    "#print(np.count_nonzero(yall==0))\n",
    "#print(np.count_nonzero(yall==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4, color='blue'>NOTE.</font>\n",
    "    \n",
    "    0 = no cloud pixel\n",
    "    1 = cloud pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's load the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PNM_A027474_20200925T082711_60m.csv', 'rb') as fd3:\n",
    "    gzip_fd3 = gzip.GzipFile(fileobj=fd3)\n",
    "    data3 = pd.read_csv(gzip_fd3)\n",
    "\n",
    "# Check print\n",
    "#print(data3.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xallpd_test = data3.iloc[:, 2:]\n",
    "indpd_test = data3.iloc[:,0]\n",
    "yallpd_test = data3.iloc[:,1]\n",
    "\n",
    "# Check prints\n",
    "#print(xallpd_test.iloc[3])\n",
    "#print(indpd_test.iloc[3])\n",
    "#print(yallpd_test.iloc[3])\n",
    "#print(xallpd_test.shape)\n",
    "#print(yallpd_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform the pandas dataframes into numpy arrays and convert the labels from 1/2 to 0/1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xall_test = pd.DataFrame(xallpd_test).to_numpy()\n",
    "indall_test = pd.DataFrame(indpd_test).to_numpy()\n",
    "yall_test = pd.DataFrame(yallpd_test).to_numpy()\n",
    "\n",
    "# Check prints\n",
    "#print(np.shape(xall_test))\n",
    "#print(np.shape(yall_test))\n",
    "\n",
    "#print(np.count_nonzero(yall_test==1))\n",
    "#print(np.count_nonzero(yall_test==2))\n",
    "\n",
    "yall_test[yall_test==1] = 0\n",
    "yall_test[yall_test==2] = 1\n",
    "\n",
    "#print(np.count_nonzero(yall_test==0))\n",
    "#print(np.count_nonzero(yall_test==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis\n",
    "\n",
    "If we could use only three key components to derive predictions instead of 13 features the running times could in theory decrease by 2/3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Compute the 3 first principal components for training data\n",
    "pca = PCA(n_components=3)\n",
    "pcacomp = pca.fit_transform(xall)\n",
    "\n",
    "xall = pcacomp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4, color='blue'>Consider if you really want to produce these figures!</font>\n",
    "\n",
    "<font size=4, color='blue'>Running these scripts is much slower than calculating the principal components..</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Create the plot 1 to illustrate the PCA results.\n",
    "color_mapping = {0: sns.xkcd_rgb['bright purple'], 1: sns.xkcd_rgb['lime'], 2: sns.xkcd_rgb['ochre']}\n",
    "colors = list(map(lambda x: color_mapping[x], yall.flatten()))\n",
    "plt.scatter(pcacomp[:,0], pcacomp[:,1], s=20, c=colors)\n",
    "plt.title(\"3 component PCA\")\n",
    "plt.xlabel(\"Pca comp 1\")\n",
    "plt.ylabel(\"Pca comp 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot 2 to illustrate the PCA results.\n",
    "color_mapping = {0: sns.xkcd_rgb['bright purple'], 1: sns.xkcd_rgb['lime'], 2: sns.xkcd_rgb['ochre']}\n",
    "colors = list(map(lambda x: color_mapping[x], yall.flatten()))\n",
    "plt.scatter(pcacomp[:,0], pcacomp[:,2], s=20, c=colors)\n",
    "plt.title(\"3 component PCA\")\n",
    "plt.xlabel(\"Pca comp 1\")\n",
    "plt.ylabel(\"Pca comp 3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot 3 to illustrate the PCA results.\n",
    "color_mapping = {0: sns.xkcd_rgb['bright purple'], 1: sns.xkcd_rgb['lime'], 2: sns.xkcd_rgb['ochre']}\n",
    "colors = list(map(lambda x: color_mapping[x], yall.flatten()))\n",
    "plt.scatter(pcacomp[:,1], pcacomp[:,2], s=20, c=colors)\n",
    "plt.title(\"3 component PCA\")\n",
    "plt.xlabel(\"Pca comp 2\")\n",
    "plt.ylabel(\"Pca comp 3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the 3 first principal components for test data\n",
    "pca_test = PCA(n_components=3)\n",
    "pcacomp_test = pca_test.fit_transform(xall_test)\n",
    "\n",
    "xall_test = pcacomp_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import random\n",
    "\n",
    "# Let's shuffle the data\n",
    "alltog1 = np.append(xall, indall, axis=1)\n",
    "alltog = np.append(alltog1, yall, axis=1)\n",
    "np.random.shuffle(alltog)\n",
    "\n",
    "xall = alltog[:,:-2]\n",
    "indall = alltog[:,-2]\n",
    "yall = alltog[:,-1]\n",
    "\n",
    "x_train = xall\n",
    "y_train = yall\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "\n",
    "# Check prints\n",
    "#print(np.shape(x_train))\n",
    "#print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's shuffle the data\n",
    "alltog1_test = np.append(xall_test, indall_test, axis=1)\n",
    "alltog_test = np.append(alltog1_test, yall_test, axis=1)\n",
    "np.random.shuffle(alltog_test)\n",
    "\n",
    "xall_test = alltog_test[:,:-2]\n",
    "indall_test = alltog_test[:,-2]\n",
    "yall_test = alltog_test[:,-1]\n",
    "\n",
    "x_test = xall_test\n",
    "y_test = yall_test\n",
    "\n",
    "scaler2 = preprocessing.StandardScaler().fit(x_test)\n",
    "x_test = scaler2.transform(x_test)\n",
    "\n",
    "# Check prints\n",
    "#print(np.shape(x_test))\n",
    "#print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 1: K Nearest Neighbours <font color='orange'>-QUITE QUICK</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Natural choice since in practice every pixel has 8 neighbouring pixels\n",
    "# Try out different values and see how it affects prediction accuracy!\n",
    "knn = KNeighborsClassifier(n_neighbors=8)\n",
    "knn.fit(x_train,y_train.flatten())\n",
    "knnpre = knn.predict(x_test)\n",
    "\n",
    "y_knnpre = np.append(knnpre.reshape((np.shape(x_test)[0],1)), indall_test.reshape((np.shape(x_test)[0],1)), axis=1)\n",
    "\n",
    "# Check prints\n",
    "#print(knnpre[:10])\n",
    "#print(y_test.flatten()[:10])\n",
    "\n",
    "# Naive implementation for calculating prediction accuracy\n",
    "#knnsum = sum(x == y for x, y in zip(knnpre, y_test.flatten()))\n",
    "#knnacc = knnsum / float(len(knnpre))\n",
    "#print(knnacc)\n",
    "\n",
    "print(knn.score(x_train, y_train))\n",
    "print(knn.score(x_test, y_test))\n",
    "\n",
    "# Let's save the obtained predictions into a txt file\n",
    "np.savetxt('knnclouds.txt', y_knnpre, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check that we are not predicting always the same label\n",
    "print(np.count_nonzero(knnpre==0))\n",
    "print(np.count_nonzero(knnpre==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 2: Ridge regression <font color='green'>-QUICK</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "# Quite typical choice\n",
    "# Try out different values and see how it affects prediction accuracy!\n",
    "alp = 1e-1\n",
    "\n",
    "rire = RidgeClassifier(alpha=alp)\n",
    "rire.fit(x_train, y_train.flatten())\n",
    "ripre = rire.predict(x_test)\n",
    "\n",
    "y_ripre = np.append(ripre.reshape((np.shape(x_test)[0],1)), indall_test.reshape((np.shape(x_test)[0],1)), axis=1)\n",
    "\n",
    "# Check prints\n",
    "#print(ripre[:10])\n",
    "#print(y_ripre[:10])\n",
    "#print(y_test.flatten()[:10])\n",
    "\n",
    "print(rire.score(x_train, y_train))\n",
    "print(rire.score(x_test, y_test))\n",
    "\n",
    "# Let's save the obtained predictions into a txt file\n",
    "np.savetxt('ridgeclouds.txt', y_ripre, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check that we are not predicting always the same label\n",
    "print(np.count_nonzero(ripre==0))\n",
    "print(np.count_nonzero(ripre==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 3: Logistic regression <font color='green'>-QUICK</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Try out different C values and see how it affects prediction accuracy!\n",
    "logre = LogisticRegression(C=1e-6)\n",
    "logre.fit(x_train, y_train.flatten())\n",
    "logpre = logre.predict(x_test)\n",
    "\n",
    "y_logpre = np.append(logpre.reshape((np.shape(x_test)[0],1)), indall_test.reshape((np.shape(x_test)[0],1)), axis=1)\n",
    "\n",
    "# Check prints\n",
    "#print(logpre[:10])\n",
    "#print(y_test.flatten()[:10])\n",
    "\n",
    "print(logre.score(x_train, y_train))\n",
    "print(logre.score(x_test, y_test))\n",
    "\n",
    "# Let's save the obtained predictions into a txt file\n",
    "np.savetxt('logreclouds.txt', y_logpre, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check that we are not predicting always the same label\n",
    "print(np.count_nonzero(logpre==0))\n",
    "print(np.count_nonzero(logpre==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 4: Support Vector Machines <font color='green'>-QUICK</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Try out different C values and see how it affects prediction accuracy!\n",
    "svm = LinearSVC(C=1e-8, dual=False)\n",
    "svm.fit(x_train, y_train.flatten())\n",
    "\n",
    "svmpre = svm.predict(x_test)\n",
    "\n",
    "y_svmpre = np.append(svmpre.reshape((np.shape(x_test)[0],1)), indall_test.reshape((np.shape(x_test)[0],1)), axis=1)\n",
    "\n",
    "print(svm.score(x_train, y_train))\n",
    "print(svm.score(x_test, y_test))\n",
    "\n",
    "# Let's save the obtained predictions into a txt file\n",
    "np.savetxt('svmclouds.txt', y_svmpre, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check that we are not predicting always the same label\n",
    "print(np.count_nonzero(svmpre==0))\n",
    "print(np.count_nonzero(svmpre==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 4.2: SVM version 2 <font color='red'>-SLOW</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "clf = make_pipeline(SVC(gamma='auto'))\n",
    "\n",
    "clf.fit(x_train, y_train.flatten())\n",
    "\n",
    "svmpre2 = clf.predict(x_test)\n",
    "\n",
    "y_svmpre2 = np.append(svmpre2.reshape((np.shape(x_test)[0],1)), indall_test.reshape((np.shape(x_test)[0],1)), axis=1)\n",
    "\n",
    "print(clf.score(x_train, y_train))\n",
    "print(clf.score(x_test, y_test))\n",
    "\n",
    "# Let's save the obtained predictions into a txt file\n",
    "np.savetxt('svmclouds2.txt', y_svmpre, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check that we are not predicting always the same label\n",
    "print(np.count_nonzero(svmpre2==0))\n",
    "print(np.count_nonzero(svmpre2==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4, color='blue'>Works well only with small amount of data!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 5: Multilayer Perceptron <font color='red'>-SLOW / DIES DURING EXECUTION</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Let's make results reproducable\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=5)\n",
    "\n",
    "model = Sequential()\n",
    "n_cols = np.shape(x_train)[1]\n",
    "model.add(Dense(2, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(\"fit begins\")\n",
    "model.fit(x_train, y_train, epochs=32, batch_size=12, validation_split=0.2, callbacks=[early_stopping_monitor],\n",
    "          use_multiprocessing=True, verbose=0)\n",
    "print(\"predicting begins\")\n",
    "mlppre = model.predict(x_test)\n",
    "\n",
    "y_mlppre = np.append(mlppre.reshape((np.shape(x_test)[0],1)), indall_test.reshape((np.shape(x_test)[0],1)), axis=1)\n",
    "\n",
    "# Check prints\n",
    "#print(mlppre[:10])\n",
    "#print(y_test.flatten()[:10])\n",
    "\n",
    "# Naive implementation for calculating accuracy\n",
    "#mlpsum = sum((x >= 0.5 and y==1) or (x<0.5 and y==0) for x, y in zip(mlppre, y_test.flatten()))\n",
    "#mlpacc = mlpsum / float(len(mlpennu))\n",
    "#print(mlpacc)\n",
    "\n",
    "print(model.evaluate(x_train, y_train)[1])\n",
    "print(model.evaluate(x_test, y_test)[1])\n",
    "\n",
    "# Let's save the obtained predictions into a txt file\n",
    "np.savetxt('mlpclouds.txt', y_mlppre, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check that we are not predicting always the same label\n",
    "print(np.count_nonzero(mlppre<0.5))\n",
    "print(np.count_nonzero(mlppre>=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Classifier 5.2: MLP version 2 <font color='red'>-SLOW / DIES DURING EXECUTION</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Let's make results reproducable\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Let's try without PCA and standardization\n",
    "x_train2 = pd.DataFrame(xallpd).to_numpy()\n",
    "y_train2 = pd.DataFrame(yallpd).to_numpy()\n",
    "\n",
    "x_test2 = pd.DataFrame(xallpd_test).to_numpy()\n",
    "y_test2 = pd.DataFrame(yallpd_test).to_numpy()\n",
    "\n",
    "y_train2[y_train2==1] = 0\n",
    "y_train2[y_train2==2] = 1\n",
    "y_test2[y_test2==1] = 0\n",
    "y_test2[y_test2==2] = 1\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=5)\n",
    "\n",
    "model2 = Sequential()\n",
    "n_cols2 = np.shape(x_train2)[1]\n",
    "model2.add(Dense(8, activation='relu', input_shape=(n_cols2,)))\n",
    "model2.add(Dense(4, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(\"fit begins\")\n",
    "model2.fit(x_train2, y_train2, epochs=32, batch_size=12, validation_split=0.2, callbacks=[early_stopping_monitor],\n",
    "          use_multiprocessing=True, verbose=0)\n",
    "print(\"ennustukset alkaa\")\n",
    "mlppre2 = model2.predict(x_test2)\n",
    "\n",
    "y_mlppre2 = np.append(mlppre2.reshape((np.shape(x_test)[0],1)), indall_test.reshape((np.shape(x_test)[0],1)), axis=1)\n",
    "\n",
    "# Check prints\n",
    "#print(mlppre2[:10])\n",
    "#print(y_test2.flatten()[:10])\n",
    "\n",
    "print(model2.evaluate(x_train2, y_train2)[1])\n",
    "print(model2.evaluate(x_test2, y_test2)[1])\n",
    "\n",
    "# Let's save the obtained predictions into a txt file\n",
    "np.savetxt('mlpclouds2.txt', y_mlppre2, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check that we are not predicting always the same label\n",
    "print(np.count_nonzero(mlppre2<0.5))\n",
    "print(np.count_nonzero(mlppre2>=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In MLPs there are exceptionally many parameters which have a crucial effect to the performance of the algorithm. You can test how different choices reflect to the execution time and performance level.\n",
    "\n",
    "Test at least to modify:\n",
    "- the structure of the neural network (more hidden layers, more / less hidden neurons per layer?)\n",
    "- number of epochs\n",
    "- batch_size\n",
    "\n",
    "Also the choice of optimizer might have a small effect. The other choices should be optimal for this use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 6: Naive Bayes <font color='green'>-QUICK</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# NOTE. Need to be done without PCA and standardization\n",
    "\n",
    "# Training data\n",
    "xall3 = pd.DataFrame(xallpd).to_numpy()\n",
    "indall3 = pd.DataFrame(indpd).to_numpy()\n",
    "yall3 = pd.DataFrame(yallpd).to_numpy()\n",
    "\n",
    "# Let's shuffle the data\n",
    "alltog3 = np.append(xall3, indall3, axis=1)\n",
    "alltog2 = np.append(alltog3, yall3, axis=1)\n",
    "np.random.shuffle(alltog2)\n",
    "\n",
    "xall2 = alltog2[:,:-2]\n",
    "indall2 = alltog2[:,-2]\n",
    "yall2 = alltog2[:,-1]\n",
    "\n",
    "x_train2 = xall2\n",
    "y_train2 = yall2\n",
    "\n",
    "# Test data\n",
    "xall_test3 = pd.DataFrame(xallpd_test).to_numpy()\n",
    "indall_test3 = pd.DataFrame(indpd_test).to_numpy()\n",
    "yall_test3 = pd.DataFrame(yallpd_test).to_numpy()\n",
    "\n",
    "# Let's shuffle the data\n",
    "alltog_test3 = np.append(xall_test3, indall_test3, axis=1)\n",
    "alltog_test2 = np.append(alltog_test3, yall_test3, axis=1)\n",
    "np.random.shuffle(alltog_test2)\n",
    "\n",
    "xall_test2 = alltog_test2[:,:-2]\n",
    "indall_test2 = alltog_test2[:,-2]\n",
    "yall_test2 = alltog_test2[:,-1]\n",
    "\n",
    "x_test2 = xall_test2\n",
    "y_test2 = yall_test2\n",
    "\n",
    "# Let's convert the labels from 1/2 to 0/1\n",
    "y_train2[y_train2==1] = 0\n",
    "y_train2[y_train2==2] = 1\n",
    "y_test2[y_test2==1] = 0\n",
    "y_test2[y_test2==2] = 1\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train2, y_train2)\n",
    "\n",
    "mnbpre = mnb.predict(x_test2)\n",
    "\n",
    "y_mnbpre = np.append(mnbpre.reshape((np.shape(x_test2)[0],1)), indall_test2.reshape((np.shape(x_test2)[0],1)), axis=1)\n",
    "\n",
    "print(mnb.score(x_train2, y_train2))\n",
    "print(mnb.score(x_test2, y_test2))\n",
    "\n",
    "# Let's save the obtained predictions into a txt file\n",
    "np.savetxt('mnbclouds.txt', y_mnbpre, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's check that we are not predicting always the same label\n",
    "print(np.count_nonzero(mnbpre==0))\n",
    "print(np.count_nonzero(mnbpre==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 7: Decision tree <font color='green'>-QUICK</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Setting a random state makes results reproducable\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(x_train, y_train)\n",
    "\n",
    "treepre = tree.predict(x_test)\n",
    "\n",
    "y_treepre = np.append(treepre.reshape((np.shape(x_test)[0],1)), indall_test.reshape((np.shape(x_test)[0],1)), axis=1)\n",
    "\n",
    "print(tree.score(x_train, y_train))\n",
    "print(tree.score(x_test, y_test))\n",
    "\n",
    "# Let's save the obtained predictions into a txt file\n",
    "np.savetxt('treeclouds.txt', y_treepre, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check that we are not predicting always the same label\n",
    "print(np.count_nonzero(treepre==0))\n",
    "print(np.count_nonzero(treepre==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 8: Random forest <font color='orange'>-QUITE QUICK</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Try out different values for n_estimators and max_depth and see how it affects prediction accuracy!\n",
    "rf = RandomForestClassifier(n_estimators=30, max_depth=9, random_state=42)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "rfpre = rf.predict(x_test)\n",
    "\n",
    "y_rfpre = np.append(rfpre.reshape((np.shape(x_test)[0],1)), indall_test.reshape((np.shape(x_test)[0],1)), axis=1)\n",
    "\n",
    "print(rf.score(x_train, y_train))\n",
    "print(rf.score(x_test, y_test))\n",
    "\n",
    "# Let's save the obtained predictions into a txt file\n",
    "np.savetxt('rfclouds.txt', y_rfpre, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check that we are not predicting always the same label\n",
    "print(np.count_nonzero(rfpre==0))\n",
    "print(np.count_nonzero(rfpre==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 9: Voting Classifier (ensemble learning) <font color='green'>-QUICK</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Try different model combinations and see how it affects prediction accuracy!\n",
    "evc = VotingClassifier(estimators=[('rire',rire),('logre',logre),('svm',svm)], voting='hard')\n",
    "evc.fit(x_train, y_train)\n",
    "\n",
    "evcpre = evc.predict(x_test)\n",
    "\n",
    "y_evcpre = np.append(evcpre.reshape((np.shape(x_test)[0],1)), indall_test.reshape((np.shape(x_test)[0],1)), axis=1)\n",
    "\n",
    "print(evc.score(x_train, y_train))\n",
    "print(evc.score(x_test, y_test))\n",
    "\n",
    "# Let's save the obtained predictions into a txt file\n",
    "np.savetxt('evcclouds.txt', y_evcpre, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check that we are not predicting always the same label\n",
    "print(np.count_nonzero(evcpre==0))\n",
    "print(np.count_nonzero(evcpre==1))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
